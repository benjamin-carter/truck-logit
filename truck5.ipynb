{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "truck5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMzpKORkSFBU/Ga/kdJolPS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benjamin-carter/truck-logit/blob/master/truck5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNVUoOmO_srD",
        "colab_type": "text"
      },
      "source": [
        "Link to Google Drive to retrieve data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kHXus27BbLK",
        "colab_type": "code",
        "outputId": "53e4faa8-f714-4232-ae5d-f4118a352309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0C6IwYr_1bH",
        "colab_type": "text"
      },
      "source": [
        "View Google Drive to confirm data is there"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llbNkbi4BiZN",
        "colab_type": "code",
        "outputId": "884436c0-0ff5-476d-d0e1-beea6dac9843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "ls \"/content/gdrive/My Drive/Current\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bias_log_reg_2.csv     NB_train_use.csv      train_clean_norm_SMOTE.csv\n",
            "bias_log_reg_3.csv     sam_bias.csv          train_last.csv\n",
            "bias_log_reg.csv       sam_weights.csv       train_new.csv\n",
            "data_test.csv          test_clean.csv        weights_log_reg_2.csv\n",
            "data_train.csv         test_clean_norm.csv   weights_log_reg_3.csv\n",
            "Full.csv               test_last.csv         weights_log_reg.csv\n",
            "house_price_class.csv  test_new.csv          X_whole.csv\n",
            "house_raw.csv          train_clean.csv\n",
            "NB_test_use.csv        train_clean_norm.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkdsb9Qv_5OZ",
        "colab_type": "text"
      },
      "source": [
        "Add necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAimMlC38AaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_w = pd.read_csv(\"/content/gdrive/My Drive/Current/weights_log_reg.csv\", header = None)\n",
        "df_b = pd.read_csv(\"/content/gdrive/My Drive/Current/bias_log_reg.csv\", header = None)\n",
        "weight_lg = df_w.to_numpy()\n",
        "bias_lg = df_b.to_numpy()\n",
        "log_reg.w = weight_lg\n",
        "log_reg.b = bias_lg\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osIwEaerBtmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import multivariate_normal as mvn\n",
        "from scipy.stats import truncnorm as trn \n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3yV71LA_8SA",
        "colab_type": "text"
      },
      "source": [
        "Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAmw2r84B5ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truck_train = pd.read_csv(\"/content/gdrive/My Drive/Current/train_clean_norm.csv\")\n",
        "X_train_tot = truck_train.to_numpy()\n",
        "\n",
        "truck_test = pd.read_csv(\"/content/gdrive/My Drive/Current/test_clean_norm.csv\")\n",
        "X_test_tot = truck_test.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1knRdb1kABlI",
        "colab_type": "text"
      },
      "source": [
        "Download full data and normalize it between 0 and 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2mCR513-I0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = pd.read_csv(\"/content/gdrive/My Drive/Current/data_train.csv\")\n",
        "data_test = pd.read_csv(\"/content/gdrive/My Drive/Current/data_test.csv\")\n",
        "# print(data_train.head())\n",
        "\n",
        "#data_train = pd.read_csv(\"/content/gdrive/My Drive/Current/train_last.csv\")\n",
        "#data_test = pd.read_csv(\"/content/gdrive/My Drive/Current/test_last.csv\")\n",
        "\n",
        "data_train.pop('cd_000')\n",
        "data_test.pop('cd_000')\n",
        "\n",
        "X_train = data_train.to_numpy()[:, 2:]\n",
        "X_test = data_test.to_numpy()[:, 2:]\n",
        "\n",
        "# print(X_train)\n",
        "\n",
        "N_train, D_train = X_train.shape\n",
        "N_test, D_test = X_test.shape\n",
        "\n",
        "if D_train != D_test:\n",
        "    print(\"Something went horribly wrong!\")\n",
        "\n",
        "else:\n",
        "    for i in range(1, D_train):\n",
        "        up = max(np.max(X_train[:, i]), np.max(X_test[:, i]))\n",
        "        down = min(np.min(X_train[:, i]), np.min(X_test[:, i]))\n",
        "\n",
        "        if (up - down) != 0:\n",
        "            X_train[:, i] = (X_train[:, i] - down) / (up - down)\n",
        "            X_test[:, i] = (X_test[:, i] - down) / (up - down)\n",
        "\n",
        "#    df = pd.DataFrame(X_train)\n",
        "#    df.columns = data_train.columns.values[2:]\n",
        "#    df.to_csv(\"train_clean_norm.csv\", header=True, index=False)\n",
        "\n",
        "#    df = pd.DataFrame(X_test)\n",
        "#    df.columns = data_test.columns.values[2:]\n",
        "#    df.to_csv(\"test_clean_norm.csv\", header=True, index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B60T8cgZAFaT",
        "colab_type": "text"
      },
      "source": [
        "Download full data, normalize it, and make binary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X55wikanNXhY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = pd.read_csv(\"/content/gdrive/My Drive/Current/data_train.csv\")\n",
        "data_test = pd.read_csv(\"/content/gdrive/My Drive/Current/data_test.csv\")\n",
        "# print(data_train.head())\n",
        "\n",
        "\n",
        "data_train.pop('cd_000')\n",
        "data_test.pop('cd_000')\n",
        "\n",
        "X_train = data_train.to_numpy()[:, 2:]\n",
        "X_test = data_test.to_numpy()[:, 2:]\n",
        "\n",
        "N_train, D_train = X_train.shape\n",
        "N_test, D_test = X_test.shape\n",
        "\n",
        "if D_train != D_test:\n",
        "    print(\"Something went horribly wrong!\")\n",
        "\n",
        "else:\n",
        "    for i in range(1, D_train):\n",
        "        up = max(np.max(X_train[:, i]), np.max(X_test[:, i]))\n",
        "        down = min(np.min(X_train[:, i]), np.min(X_test[:, i]))\n",
        "\n",
        "        if (up - down) != 0:\n",
        "            X_train[:, i] = (X_train[:, i] - down) / (up - down)\n",
        "            X_test[:, i] = (X_test[:, i] - down) / (up - down)\n",
        "\n",
        "N,D = X_train.shape\n",
        "for j in range(D): \n",
        "  X_train[:,j] = np.around(X_train[:,j])\n",
        "N,D = X_test.shape\n",
        "for j in range(D): \n",
        "  X_test[:,j] = np.around(X_test[:,j])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otnv2c6ODrkC",
        "colab_type": "text"
      },
      "source": [
        "Download full data and make binary without normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2qVAg4qt4KC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = pd.read_csv(\"/content/gdrive/My Drive/Current/data_train.csv\")\n",
        "data_test = pd.read_csv(\"/content/gdrive/My Drive/Current/data_test.csv\")\n",
        "# print(data_train.head())\n",
        "\n",
        "\n",
        "data_train.pop('cd_000')\n",
        "data_test.pop('cd_000')\n",
        "\n",
        "X_train = data_train.to_numpy()[:, 2:]\n",
        "X_test = data_test.to_numpy()[:, 2:]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RU84OBdmnDF",
        "colab_type": "text"
      },
      "source": [
        "Download SMOTE test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79LeiBmWmmmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = pd.read_csv(\"/content/gdrive/My Drive/Current/train_clean_norm_SMOTE.csv\")\n",
        "data_test = pd.read_csv(\"/content/gdrive/My Drive/Current/data_test.csv\")\n",
        "\n",
        "\n",
        "data_test.pop('cd_000')\n",
        "\n",
        "X_train = data_train.to_numpy()\n",
        "X_test = data_test.to_numpy()[:, 2:]\n",
        "\n",
        "# print(X_train)\n",
        "\n",
        "N_test, D_test = X_test.shape\n",
        "\n",
        "\n",
        "if D_train != D_test:\n",
        "    print(\"Something went horribly wrong!\")\n",
        "\n",
        "else:\n",
        "    for i in range(1, D_test):\n",
        "        up = np.max(X_test[:, i])\n",
        "        down = np.min(X_test[:, i])\n",
        "\n",
        "        if (up - down) != 0:\n",
        "            X_test[:, i] = (X_test[:, i] - down) / (up - down)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0IrE-PEF_e4",
        "colab_type": "text"
      },
      "source": [
        "Universal Functions declared and defined"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaIrfYaMDeI4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(h):\n",
        "  return 1/(1 + np.exp(-h))\n",
        "\n",
        "def cross_entropy(Y, P_hat):\n",
        "  return -(1/len(Y))*np.sum(np.sum(Y*np.log(P_hat), axis=1), axis=0)\n",
        "\n",
        "def accuracy(y, y_hat):\n",
        "  return np.mean(y == y_hat)\n",
        "\n",
        "def confusion(y, y_hat):\n",
        "  confuse = np.zeros((2,2))\n",
        "  confuse[0,0] = np.sum(y_hat[y == 1])\n",
        "  confuse[0,1] = np.sum(y_hat[y == 0])\n",
        "  confuse[1,0] = np.count_nonzero(y_hat[y == 1] == 0)\n",
        "  confuse[1,1] = np.count_nonzero(y_hat[y == 0] == 0)\n",
        "  return confuse\n",
        "\n",
        "def cost(y, y_hat):\n",
        "  cost = np.zeros((2,2))\n",
        "  cost[0,1] = np.sum(y_hat[y == 0]) * 10\n",
        "  cost[1,0] = np.count_nonzero(y_hat[y == 1] == 0) * 500\n",
        "  return cost\n",
        "\n",
        "def percent(y, y_hat):\n",
        "  confuse = np.zeros((2,2))\n",
        "  confuse[0,0] = np.sum(y_hat[y == 1]) / np.sum(y)\n",
        "  confuse[0,1] = np.sum(y_hat[y == 0]) / np.count_nonzero(y == 0)\n",
        "  confuse[1,0] = np.count_nonzero(y_hat[y == 1] == 0) / np.sum(y)\n",
        "  confuse[1,1] = np.count_nonzero(y_hat[y == 0] == 0) / np.count_nonzero(y == 0)\n",
        "  return confuse\n",
        "\n",
        "def indices_to_one_hot(data, nb_classes):\n",
        "  #converts on iterable of indices to one hot labels\n",
        "  targets = np.array(data).reshape(-1)\n",
        "  #targets.astype(int)\n",
        "  #nb_classes.astype(int)\n",
        "  return np.eye(nb_classes)[targets]\n",
        "\n",
        "def softmax(h):\n",
        "  return (np.exp(h.T) / np.sum(np.exp(h), axis =1)).T\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwkvgsHkF6cg",
        "colab_type": "text"
      },
      "source": [
        "Logistic Regression class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7GvyJITCu9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression():\n",
        "\n",
        "  def __init__(self, thresh = 0.7):\n",
        "    self.thresh = thresh\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "\n",
        "  def fit(self, X, y, eta = 1e-3, epochs = 1e5,show_curve = False):\n",
        "    epochs = int(epochs)\n",
        "    N,D = X.shape\n",
        "\n",
        "    #self.w = np.random.randn(D)\n",
        "    #self.b = np.random.randn(1)\n",
        "\n",
        "    J = np.zeros(epochs)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      p_hat = self.__forward(X)\n",
        "      J[epoch] = cross_entropy(y, p_hat)\n",
        "      self.w -= eta * (1/N) * X.T@(p_hat - y)\n",
        "      self.b -= eta * (1/N) * np.sum(p_hat - y)\n",
        "\n",
        "    if show_curve:\n",
        "      plt.figure()\n",
        "      plt.plot(J)\n",
        "      plt.xlabel(\"epochs\")\n",
        "      plt.ylabel(\"J\")\n",
        "      plt.title(\"Training Curve\")\n",
        "      plt.show()\n",
        "\n",
        "  def __forward(self, X):\n",
        "    return sigmoid(X@self.w + self.b)\n",
        "\n",
        "  def predict(self, X):\n",
        "    return (self.__forward(X) >= self.thresh).astype(np.int32)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGG-e1yaoZAm",
        "colab_type": "text"
      },
      "source": [
        "Generalized Logistic Regression Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XHvkbw0ObIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GenLogisticRegression():\n",
        "  \n",
        "  def __init__(self, thresh = 0.5):\n",
        "    self.W = None\n",
        "    self.B = None\n",
        "\n",
        "  def fit(self, X, y, eta = 1e-2, epochs = 1e4, show_curve = False):\n",
        "    N,D = X.shape\n",
        "    epochs = int(epochs)\n",
        "    K = len(np.unique(y))\n",
        "    \n",
        "    self.y_values = np.unique(y, return_index=False)\n",
        "    Y = indices_to_one_hot(y, K).astype(int)\n",
        "\n",
        "    #self.W = np.random.randn(D, K)\n",
        "    #self.B = np.random.randn(K)\n",
        "\n",
        "    J = np.zeros(int(epochs))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "      P_hat = self.__forward__(X)\n",
        "      J[epoch] = cross_entropy(Y, P_hat)\n",
        "      self.W -= eta * (1/N) * X.T@(P_hat - Y)\n",
        "      self.B -= eta * (1/N) * np.sum(P_hat - Y, axis = 0)\n",
        "\n",
        "    if show_curve:\n",
        "      plt.figure()\n",
        "      plt.plot(J)\n",
        "      plt.xlabel(\"epochs\")\n",
        "      plt.ylabel(\"J\")\n",
        "      plt.title(\"Training Curve\")\n",
        "      plt.show()\n",
        "\n",
        "  def __forward__(self, X):\n",
        "    return softmax(X @ self.W + self.B)\n",
        "\n",
        "  def predict(self, X):\n",
        "    return np.argmax(self.__forward__(X),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_8sf9-PAWXV",
        "colab_type": "text"
      },
      "source": [
        "Undersampling Majority"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RVbYVFF3sbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_fail = X_train[X_train[:,0] == 1,:]\n",
        "X_train_nonfail = X_train[X_train[:,0] == 0, :]\n",
        "np.random.shuffle(X_train_nonfail)\n",
        "X_temp = np.concatenate((X_train_fail, X_train_nonfail[:30000, :]))\n",
        "X_trial_5 = X_temp\n",
        "Y_train = X_temp[:,0]\n",
        "X_train = X_temp[:,1:]\n",
        "Y_test = X_test[:,0]\n",
        "X_test = X_test[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_lqWNs-DzBU",
        "colab_type": "text"
      },
      "source": [
        "Oversampling Minority"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Tx-K5WiAZUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_fail = X_train[X_train[:,0] == 1,:]\n",
        "X_train_nonfail = X_train[X_train[:,0] == 0, :]\n",
        "np.random.shuffle(X_train_nonfail)\n",
        "H = 29\n",
        "X_temp = np.concatenate((X_train_fail, X_train_nonfail))\n",
        "for i in range(H):\n",
        "  X_temp = np.concatenate((X_train_fail, X_temp))\n",
        "np.random.shuffle(X_temp)\n",
        "X_trial_ = X_temp\n",
        "Y_train = X_temp[:,0]\n",
        "X_train = X_temp[:,1:]\n",
        "Y_test = X_test[:,0]\n",
        "X_test = X_test[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07CZxvWIFni5",
        "colab_type": "text"
      },
      "source": [
        "No change in Failure / Nonfailure proportion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jva7ehDR7VqL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_train = X_train[:,0]\n",
        "X_train = X_train[:,1:]\n",
        "Y_test = X_test[:,0]\n",
        "X_test = X_test[:,1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoFNKHF8kDL6",
        "colab_type": "text"
      },
      "source": [
        "Change data to binary once the target and features have been split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE3giQO1jcFY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = 650\n",
        "t2 = 2125\n",
        "X_train[np.where(X_train <= t1)] = 0\n",
        "X_train[np.where(X_train > t1)] = 1\n",
        "X_test[np.where(X_test <= t2)] = 0\n",
        "X_test[np.where(X_test > t2)] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHULP_sVFwP4",
        "colab_type": "text"
      },
      "source": [
        "Run Logistic Regression and print the confusion matrix and cost output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qt3Rhd2vtfhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, Y_train, show_curve = True)\n",
        "y_hat = log_reg.predict(X_test)\n",
        "print(confusion(Y_test, y_hat))\n",
        "print(cost(Y_test, y_hat))\n",
        "mat_temp = cost(Y_test, y_hat)\n",
        "print(mat_temp[0,1] + mat_temp[1,0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afwh2uIQom0_",
        "colab_type": "text"
      },
      "source": [
        "Upload Weights in order to submit final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVM7Ig6YKNR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(log_reg.w)\n",
        "df.to_csv(\"/content/gdrive/My Drive/Current/weights_log_reg.csv\", header=False, index=False)\n",
        "\n",
        "df = pd.DataFrame(log_reg.b)\n",
        "df.to_csv(\"/content/gdrive/My Drive/Current/bias_log_reg.csv\", header=False, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2_XScGwot8P",
        "colab_type": "text"
      },
      "source": [
        "Smaller dataset based on high correlation variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ntCIJac9L_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "truck_train2 = truck_train[['class', 'aa_000', 'bb_000', 'aq_000',  'ah_000', 'cc_000', 'an_000', 'bg_000', 'bx_000', 'ap_000', 'ee_005', 'ba_004', 'ck_000', 'ba_003', 'ba_005',  'ag_005', 'ee_002', 'cs_004', 'ag_003', 'az_005', 'ba_000', 'ee_003', 'ba_002', 'ee_004', 'ee_006', 'ee_000', 'ay_008', 'cn_003', 'cs_003', 'cn_001', 'cs_002', 'ag_004', 'ag_006', 'cn_002', 'al_000', 'ee_001', 'az_004', 'cs_000', 'ed_000', 'ag_002', 'ba_007', 'dt_000', 'ds_000', 'cm_000', 'cs_001', 'cj_000', 'ec_00',  'ay_007', 'dd_000', 'do_000', 'az_001']]\n",
        "\n",
        "truck_test2 = truck_test[['class', 'aa_000', 'bb_000', 'aq_000',  'ah_000', 'cc_000', 'an_000', 'bg_000', 'bx_000', 'ap_000', 'ee_005', 'ba_004', 'ck_000', 'ba_003', 'ba_005',  'ag_005', 'ee_002', 'cs_004', 'ag_003', 'az_005', 'ba_000', 'ee_003', 'ba_002', 'ee_004', 'ee_006', 'ee_000', 'ay_008', 'cn_003', 'cs_003', 'cn_001', 'cs_002', 'ag_004', 'ag_006', 'cn_002', 'al_000', 'ee_001', 'az_004', 'cs_000', 'ed_000', 'ag_002', 'ba_007', 'dt_000', 'ds_000', 'cm_000', 'cs_001', 'cj_000', 'ec_00',  'ay_007', 'dd_000', 'do_000', 'az_001']]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}